{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a7269127",
   "metadata": {},
   "source": [
    "### Classification Network - All Embeddings - One-Hot grouping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1fd8f48b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\dlezo\\AppData\\Roaming\\Python\\Python311\\site-packages\\pandas\\core\\arrays\\masked.py:60: UserWarning: Pandas requires version '1.3.6' or newer of 'bottleneck' (version '1.3.5' currently installed).\n",
      "  from pandas.core import (\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras import Sequential\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.layers import Dense, Dropout, Input\n",
    "from tensorflow.keras.losses import BinaryCrossentropy, CategoricalCrossentropy, \\\n",
    "CategoricalHinge, BinaryFocalCrossentropy,\\\n",
    "MeanSquaredError, LogCosh, CosineSimilarity, Huber, MeanSquaredLogarithmicError, MeanAbsoluteError\n",
    "\n",
    "import pandas as pd\n",
    "import pickle\n",
    "import numpy as np\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_squared_error, r2_score, mean_absolute_error, f1_score\n",
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score\n",
    "\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "21ad721c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# tf.config.list_physical_devices('GPU')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d4ae16d",
   "metadata": {},
   "source": [
    "#### Load the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "29f9f39e",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total pairs: 155137\n",
      "Has/Doesn't have class_00 100000 / 55137\n",
      "Has/Doesn't have class_01 46981 / 108156\n",
      "Has/Doesn't have class_02 50429 / 104708\n",
      "Has/Doesn't have class_03 13274 / 141863\n",
      "Has/Doesn't have class_04 53738 / 101399\n",
      "Has/Doesn't have class_05 19342 / 135795\n",
      "Has/Doesn't have class_06 54162 / 100975\n",
      "Has/Doesn't have class_07 28799 / 126338\n",
      "Has/Doesn't have class_08 29005 / 126132\n",
      "Has/Doesn't have class_09 31261 / 123876\n",
      "Has/Doesn't have class_10 54575 / 100562\n",
      "Has/Doesn't have class_11 51810 / 103327\n",
      "Has/Doesn't have class_12 47356 / 107781\n",
      "Has/Doesn't have class_13 52445 / 102692\n",
      "Has/Doesn't have class_14 20528 / 134609\n",
      "Has/Doesn't have class_15 52627 / 102510\n",
      "Has/Doesn't have class_16 45863 / 109274\n",
      "Has/Doesn't have class_17 40630 / 114507\n",
      "Has/Doesn't have class_19 17600 / 137537\n",
      "Has/Doesn't have class_20 53792 / 101345\n",
      "Has/Doesn't have class_21 44431 / 110706\n",
      "Has/Doesn't have class_22 13823 / 141314\n",
      "Has/Doesn't have class_23 52057 / 103080\n",
      "Has/Doesn't have class_24 42749 / 112388\n",
      "Has/Doesn't have class_25 48962 / 106175\n",
      "Has/Doesn't have class_26 51268 / 103869\n",
      "Has/Doesn't have class_27 5602 / 149535\n",
      "Has/Doesn't have class_28 52445 / 102692\n",
      "Has/Doesn't have class_29 38470 / 116667\n",
      "Has/Doesn't have class_30 51665 / 103472\n",
      "Has/Doesn't have class_31 44711 / 110426\n",
      "Has/Doesn't have class_32 47628 / 107509\n",
      "Has/Doesn't have class_33 45606 / 109531\n",
      "Has/Doesn't have class_34 50413 / 104724\n",
      "Has/Doesn't have class_35 53243 / 101894\n",
      "Has/Doesn't have class_36 53097 / 102040\n",
      "Has/Doesn't have class_37 47708 / 107429\n",
      "Has/Doesn't have class_38 35873 / 119264\n",
      "Has/Doesn't have class_39 38473 / 116664\n",
      "Has/Doesn't have class_40 25939 / 129198\n",
      "Has/Doesn't have class_41 52978 / 102159\n",
      "Has/Doesn't have class_42 10508 / 144629\n",
      "Has/Doesn't have class_43 48346 / 106791\n",
      "Has/Doesn't have class_44 17365 / 137772\n",
      "Has/Doesn't have class_46 52488 / 102649\n",
      "Has/Doesn't have class_47 51813 / 103324\n",
      "Has/Doesn't have class_48 23027 / 132110\n",
      "Has/Doesn't have class_49 51658 / 103479\n",
      "Has/Doesn't have class_50 22459 / 132678\n",
      "Has/Doesn't have class_51 7370 / 147767\n",
      "Has/Doesn't have class_52 12433 / 142704\n",
      "Has/Doesn't have class_53 42173 / 112964\n",
      "Has/Doesn't have class_54 52942 / 102195\n",
      "Has/Doesn't have class_55 22410 / 132727\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>drug1</th>\n",
       "      <th>drug2</th>\n",
       "      <th>class_00</th>\n",
       "      <th>class_01</th>\n",
       "      <th>class_02</th>\n",
       "      <th>class_03</th>\n",
       "      <th>class_04</th>\n",
       "      <th>class_05</th>\n",
       "      <th>class_06</th>\n",
       "      <th>class_07</th>\n",
       "      <th>...</th>\n",
       "      <th>class_46</th>\n",
       "      <th>class_47</th>\n",
       "      <th>class_48</th>\n",
       "      <th>class_49</th>\n",
       "      <th>class_50</th>\n",
       "      <th>class_51</th>\n",
       "      <th>class_52</th>\n",
       "      <th>class_53</th>\n",
       "      <th>class_54</th>\n",
       "      <th>class_55</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>55681</td>\n",
       "      <td>1243041</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>134547</td>\n",
       "      <td>6313</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4094</td>\n",
       "      <td>47858</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>8627</td>\n",
       "      <td>3920</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>797195</td>\n",
       "      <td>41493</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>155132</th>\n",
       "      <td>4448</td>\n",
       "      <td>32675</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>155133</th>\n",
       "      <td>4821</td>\n",
       "      <td>4816</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>155134</th>\n",
       "      <td>1998</td>\n",
       "      <td>7781</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>155135</th>\n",
       "      <td>20220</td>\n",
       "      <td>7398</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>155136</th>\n",
       "      <td>39786</td>\n",
       "      <td>5764</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>155137 rows × 58 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         drug1    drug2  class_00  class_01  class_02  class_03  class_04  \\\n",
       "0        55681  1243041       1.0       0.0       0.0       0.0       0.0   \n",
       "1       134547     6313       0.0       0.0       1.0       0.0       1.0   \n",
       "2         4094    47858       1.0       0.0       0.0       0.0       0.0   \n",
       "3         8627     3920       1.0       0.0       0.0       0.0       0.0   \n",
       "4       797195    41493       0.0       1.0       1.0       0.0       1.0   \n",
       "...        ...      ...       ...       ...       ...       ...       ...   \n",
       "155132    4448    32675       1.0       0.0       0.0       0.0       0.0   \n",
       "155133    4821     4816       0.0       0.0       1.0       0.0       1.0   \n",
       "155134    1998     7781       0.0       1.0       1.0       0.0       1.0   \n",
       "155135   20220     7398       1.0       0.0       0.0       0.0       0.0   \n",
       "155136   39786     5764       0.0       1.0       1.0       1.0       1.0   \n",
       "\n",
       "        class_05  class_06  class_07  ...  class_46  class_47  class_48  \\\n",
       "0            0.0       0.0       0.0  ...       0.0       0.0       0.0   \n",
       "1            0.0       1.0       0.0  ...       1.0       1.0       0.0   \n",
       "2            0.0       0.0       0.0  ...       0.0       0.0       0.0   \n",
       "3            0.0       0.0       0.0  ...       0.0       0.0       0.0   \n",
       "4            0.0       1.0       1.0  ...       1.0       1.0       0.0   \n",
       "...          ...       ...       ...  ...       ...       ...       ...   \n",
       "155132       0.0       0.0       0.0  ...       0.0       0.0       0.0   \n",
       "155133       1.0       1.0       0.0  ...       1.0       1.0       0.0   \n",
       "155134       0.0       1.0       0.0  ...       1.0       1.0       1.0   \n",
       "155135       0.0       0.0       0.0  ...       0.0       0.0       0.0   \n",
       "155136       1.0       1.0       1.0  ...       1.0       1.0       1.0   \n",
       "\n",
       "        class_49  class_50  class_51  class_52  class_53  class_54  class_55  \n",
       "0            0.0       0.0       0.0       0.0       0.0       0.0       0.0  \n",
       "1            1.0       1.0       0.0       0.0       1.0       1.0       0.0  \n",
       "2            0.0       0.0       0.0       0.0       0.0       0.0       0.0  \n",
       "3            0.0       0.0       0.0       0.0       0.0       0.0       0.0  \n",
       "4            1.0       0.0       0.0       0.0       1.0       1.0       0.0  \n",
       "...          ...       ...       ...       ...       ...       ...       ...  \n",
       "155132       0.0       0.0       0.0       0.0       0.0       0.0       0.0  \n",
       "155133       1.0       0.0       0.0       0.0       0.0       1.0       1.0  \n",
       "155134       1.0       1.0       0.0       0.0       1.0       1.0       1.0  \n",
       "155135       0.0       0.0       0.0       0.0       0.0       0.0       0.0  \n",
       "155136       1.0       1.0       1.0       1.0       1.0       1.0       1.0  \n",
       "\n",
       "[155137 rows x 58 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "seen = pd.read_csv('./Data/C56_71_TWOSIDES_one_hot_train.csv')\n",
    "unseen = pd.read_csv('./Data/C56_71_TWOSIDES_one_hot_test.csv')\n",
    "\n",
    "selected_classes = [\n",
    " 'class_00', 'class_01', 'class_02', 'class_03', 'class_04', 'class_05', 'class_06', 'class_07', 'class_08', 'class_09',\n",
    " 'class_10', 'class_11', 'class_12', 'class_13', 'class_14', 'class_15', 'class_16', 'class_17',             'class_19',\n",
    " 'class_20', 'class_21', 'class_22', 'class_23', 'class_24', 'class_25', 'class_26', 'class_27', 'class_28', 'class_29',\n",
    " 'class_30', 'class_31', 'class_32', 'class_33', 'class_34', 'class_35', 'class_36', 'class_37', 'class_38', 'class_39',\n",
    " 'class_40', 'class_41', 'class_42', 'class_43', 'class_44',             'class_46', 'class_47', 'class_48', 'class_49',\n",
    " 'class_50', 'class_51', 'class_52', 'class_53', 'class_54', 'class_55'\n",
    "]\n",
    "unseen_classes = ['class_18', 'class_45']\n",
    "class_columns = selected_classes\n",
    "unseen_columns = unseen_classes\n",
    "\n",
    "\n",
    "print('Total pairs:', seen.shape[0])\n",
    "for column in class_columns:\n",
    "    print('Has/Doesn\\'t have', column, seen[seen[column] == 1.0].shape[0], '/', seen[seen[column] == 0.0].shape[0])\n",
    "        \n",
    "seen    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ced96de",
   "metadata": {},
   "source": [
    "#### Load the Embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "cb31be79",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Seen shape: (155137, 59)\n",
      "Unseen shape: (103560, 6)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>drug1</th>\n",
       "      <th>drug2</th>\n",
       "      <th>class_00</th>\n",
       "      <th>class_01</th>\n",
       "      <th>class_02</th>\n",
       "      <th>class_03</th>\n",
       "      <th>class_04</th>\n",
       "      <th>class_05</th>\n",
       "      <th>class_06</th>\n",
       "      <th>class_07</th>\n",
       "      <th>...</th>\n",
       "      <th>class_47</th>\n",
       "      <th>class_48</th>\n",
       "      <th>class_49</th>\n",
       "      <th>class_50</th>\n",
       "      <th>class_51</th>\n",
       "      <th>class_52</th>\n",
       "      <th>class_53</th>\n",
       "      <th>class_54</th>\n",
       "      <th>class_55</th>\n",
       "      <th>embedded</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>55681</td>\n",
       "      <td>1243041</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>[2.168276786804199, 1.0936528444290161, 0.9610...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>134547</td>\n",
       "      <td>6313</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>[2.232297420501709, 0.9437393546104431, 0.0993...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4094</td>\n",
       "      <td>47858</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>[-0.5903611183166504, -1.876413106918335, 1.70...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>8627</td>\n",
       "      <td>3920</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>[-0.37425464391708374, 1.5704320669174194, -0....</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>797195</td>\n",
       "      <td>41493</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>[3.0385594367980957, 0.587708055973053, 0.8335...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 59 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    drug1    drug2  class_00  class_01  class_02  class_03  class_04  \\\n",
       "0   55681  1243041       1.0       0.0       0.0       0.0       0.0   \n",
       "1  134547     6313       0.0       0.0       1.0       0.0       1.0   \n",
       "2    4094    47858       1.0       0.0       0.0       0.0       0.0   \n",
       "3    8627     3920       1.0       0.0       0.0       0.0       0.0   \n",
       "4  797195    41493       0.0       1.0       1.0       0.0       1.0   \n",
       "\n",
       "   class_05  class_06  class_07  ...  class_47  class_48  class_49  class_50  \\\n",
       "0       0.0       0.0       0.0  ...       0.0       0.0       0.0       0.0   \n",
       "1       0.0       1.0       0.0  ...       1.0       0.0       1.0       1.0   \n",
       "2       0.0       0.0       0.0  ...       0.0       0.0       0.0       0.0   \n",
       "3       0.0       0.0       0.0  ...       0.0       0.0       0.0       0.0   \n",
       "4       0.0       1.0       1.0  ...       1.0       0.0       1.0       0.0   \n",
       "\n",
       "   class_51  class_52  class_53  class_54  class_55  \\\n",
       "0       0.0       0.0       0.0       0.0       0.0   \n",
       "1       0.0       0.0       1.0       1.0       0.0   \n",
       "2       0.0       0.0       0.0       0.0       0.0   \n",
       "3       0.0       0.0       0.0       0.0       0.0   \n",
       "4       0.0       0.0       1.0       1.0       0.0   \n",
       "\n",
       "                                            embedded  \n",
       "0  [2.168276786804199, 1.0936528444290161, 0.9610...  \n",
       "1  [2.232297420501709, 0.9437393546104431, 0.0993...  \n",
       "2  [-0.5903611183166504, -1.876413106918335, 1.70...  \n",
       "3  [-0.37425464391708374, 1.5704320669174194, -0....  \n",
       "4  [3.0385594367980957, 0.587708055973053, 0.8335...  \n",
       "\n",
       "[5 rows x 59 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "with open('./Data/Embeddings/biobert_embeddings_128_pca.pkl', 'rb') as file:\n",
    "    biobert = pickle.load(file)    \n",
    "with open('./Data/Embeddings/chemberta_embeddings_128_pca.pkl', 'rb') as file:\n",
    "    chemberta = pickle.load(file)    \n",
    "with open('./Data/Embeddings/kg_bio2rdf_embeddings_128_pca.pkl', 'rb') as file:\n",
    "    bio2rdf = pickle.load(file)    \n",
    "with open('./Data/Embeddings/ssp_embeddings_128_pca.pkl', 'rb') as file:\n",
    "    ssp = pickle.load(file)    \n",
    "\n",
    "drugs = set(np.concatenate([\n",
    "    seen['drug1'].unique(), seen['drug2'].unique(), unseen['drug1'].unique(), unseen['drug2'].unique()\n",
    "]))\n",
    "embeddings = {}\n",
    "for rx_norm_id in list(drugs):\n",
    "    embeddings[rx_norm_id] = np.concatenate([\n",
    "        biobert[rx_norm_id], chemberta[rx_norm_id], bio2rdf[rx_norm_id], ssp[rx_norm_id]\n",
    "    ])\n",
    "\n",
    "seen['embedded'] = seen.apply(lambda x: pd.Series(\n",
    "    [np.concatenate([embeddings[x['drug1']], embeddings[x['drug2']]])], \n",
    "    index=['embedded']), axis=1)\n",
    "print('Seen shape:', seen.shape)\n",
    "unseen['embedded'] = unseen.apply(lambda x: pd.Series(\n",
    "    [np.concatenate([embeddings[x['drug1']], embeddings[x['drug2']]])], \n",
    "    index=['embedded']), axis=1)\n",
    "print('Unseen shape:', unseen.shape)\n",
    "seen.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "675e10f1",
   "metadata": {},
   "source": [
    "#### Load and Split Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8bfa1cab",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "input size: 1024 output size: 54\n"
     ]
    }
   ],
   "source": [
    "size = len(seen['embedded'][0])\n",
    "# Get all the target columns from seen\n",
    "target_columns = seen.columns[pd.Series(seen.columns).str.startswith('class_')]\n",
    "targets = len(target_columns)\n",
    "print('input size:', size, 'output size:', targets)\n",
    "\n",
    "random_seed = 1 #42 #73 # 71\n",
    "\n",
    "x_train, x_test, y_train, y_test = train_test_split (\n",
    "    np.concatenate(seen['embedded'].values).reshape(-1, size), \n",
    "    seen[target_columns].values, test_size=1, random_state=random_seed)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aacd597f",
   "metadata": {},
   "source": [
    "#### Experiment function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "05fb99fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_experiment(name, model_size, dropout_rate, in_size, targets, \\\n",
    "                   activation_function, loss_function, learning_rate, metric, \\\n",
    "                   x_train, y_train, x_test, y_test, \n",
    "                   epochs, batch_size, validation_split, verbose=0\\\n",
    "                  ):\n",
    "    # Creating model using the Sequential in tensorflow\n",
    "    model = Sequential([\n",
    "                Input(shape=(in_size,)),\n",
    "                Dense(in_size//model_size, activation='relu'),\n",
    "                Dropout(dropout_rate),\n",
    "                Dense(in_size//model_size, activation='relu'),\n",
    "                Dropout(dropout_rate),\n",
    "                Dense(in_size//model_size, activation='relu'),\n",
    "                Dropout(dropout_rate),\n",
    "                Dense(in_size//model_size, activation='relu'),\n",
    "                Dropout(dropout_rate),\n",
    "                Dense(in_size//model_size//4, activation='relu'),\n",
    "                Dropout(dropout_rate),\n",
    "                Dense(targets, activation=activation_function)\n",
    "            ])\n",
    "    model.compile(\n",
    "        loss=loss_function,\n",
    "        optimizer=Adam(learning_rate=learning_rate),\n",
    "        metrics = [metric]\n",
    "    )\n",
    "    if verbose > 0:\n",
    "        print(model.summary())\n",
    "    filename = name+'_'+loss_function.name+'_'+str(learning_rate)+'_'+\\\n",
    "               metric+'_'+str(epochs)+'_'+str(batch_size)+'_'+\\\n",
    "               str(validation_split)+'_'+str(model_size)+'_'+\\\n",
    "               str(dropout_rate)+'_'+str(in_size)+'_'+str(targets)+\\\n",
    "               '.pkl'\n",
    "    filename = name+'.pkl'\n",
    "    print('Fitting', filename)\n",
    "    history = model.fit(\n",
    "        x_train,\n",
    "        y_train,\n",
    "        epochs=epochs,\n",
    "        batch_size=batch_size,\n",
    "        validation_split=validation_split,\n",
    "        verbose=verbose,\n",
    "        callbacks=[]\n",
    "    )\n",
    "    train_loss, train_accuracy = model.evaluate(x_train, y_train, verbose=0)\n",
    "    test_loss, test_accuracy = model.evaluate(x_test, y_test, verbose=0)\n",
    "    with open(filename, 'wb') as file:\n",
    "        pickle.dump(model, file)\n",
    "        pickle.dump(history, file)\n",
    "    print('========================================================================================')\n",
    "    print('=', filename)\n",
    "    print('========================================================================================')\n",
    "    print(f'= Model loss, accuracy on the train set: {train_loss:.5f} {100*train_accuracy:.2f}')\n",
    "    print(f'= Model loss, accuracy on the  test set: {test_loss:.5f} {100*test_accuracy:.2f}')\n",
    "    print('========================================================================================')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3f6664b",
   "metadata": {},
   "source": [
    "### Run Experiments"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e612544",
   "metadata": {},
   "source": [
    "#### Run single experiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "72267d09",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"sequential\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                         </span>┃<span style=\"font-weight: bold\"> Output Shape                </span>┃<span style=\"font-weight: bold\">         Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n",
       "│ dense (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                        │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1024</span>)                │       <span style=\"color: #00af00; text-decoration-color: #00af00\">1,049,600</span> │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dropout (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)                    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1024</span>)                │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dense_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1024</span>)                │       <span style=\"color: #00af00; text-decoration-color: #00af00\">1,049,600</span> │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dropout_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)                  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1024</span>)                │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dense_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1024</span>)                │       <span style=\"color: #00af00; text-decoration-color: #00af00\">1,049,600</span> │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dropout_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)                  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1024</span>)                │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dense_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1024</span>)                │       <span style=\"color: #00af00; text-decoration-color: #00af00\">1,049,600</span> │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dropout_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)                  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1024</span>)                │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dense_4 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)                 │         <span style=\"color: #00af00; text-decoration-color: #00af00\">262,400</span> │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dropout_4 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)                  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)                 │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dense_5 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">54</span>)                  │          <span style=\"color: #00af00; text-decoration-color: #00af00\">13,878</span> │\n",
       "└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                        \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape               \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m        Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n",
       "│ dense (\u001b[38;5;33mDense\u001b[0m)                        │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1024\u001b[0m)                │       \u001b[38;5;34m1,049,600\u001b[0m │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dropout (\u001b[38;5;33mDropout\u001b[0m)                    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1024\u001b[0m)                │               \u001b[38;5;34m0\u001b[0m │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dense_1 (\u001b[38;5;33mDense\u001b[0m)                      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1024\u001b[0m)                │       \u001b[38;5;34m1,049,600\u001b[0m │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dropout_1 (\u001b[38;5;33mDropout\u001b[0m)                  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1024\u001b[0m)                │               \u001b[38;5;34m0\u001b[0m │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dense_2 (\u001b[38;5;33mDense\u001b[0m)                      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1024\u001b[0m)                │       \u001b[38;5;34m1,049,600\u001b[0m │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dropout_2 (\u001b[38;5;33mDropout\u001b[0m)                  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1024\u001b[0m)                │               \u001b[38;5;34m0\u001b[0m │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dense_3 (\u001b[38;5;33mDense\u001b[0m)                      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1024\u001b[0m)                │       \u001b[38;5;34m1,049,600\u001b[0m │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dropout_3 (\u001b[38;5;33mDropout\u001b[0m)                  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1024\u001b[0m)                │               \u001b[38;5;34m0\u001b[0m │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dense_4 (\u001b[38;5;33mDense\u001b[0m)                      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m)                 │         \u001b[38;5;34m262,400\u001b[0m │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dropout_4 (\u001b[38;5;33mDropout\u001b[0m)                  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m)                 │               \u001b[38;5;34m0\u001b[0m │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dense_5 (\u001b[38;5;33mDense\u001b[0m)                      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m54\u001b[0m)                  │          \u001b[38;5;34m13,878\u001b[0m │\n",
       "└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">4,474,678</span> (17.07 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m4,474,678\u001b[0m (17.07 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">4,474,678</span> (17.07 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m4,474,678\u001b[0m (17.07 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "None\n",
      "Fitting TWOSIDES_00.pkl\n",
      "Epoch 1/100\n",
      "\u001b[1m1242/1242\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m52s\u001b[0m 40ms/step - binary_accuracy: 0.7639 - loss: 0.4794 - val_binary_accuracy: 0.8468 - val_loss: 0.3420\n",
      "Epoch 2/100\n",
      "\u001b[1m1242/1242\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m50s\u001b[0m 40ms/step - binary_accuracy: 0.8434 - loss: 0.3427 - val_binary_accuracy: 0.8560 - val_loss: 0.3188\n",
      "Epoch 3/100\n",
      "\u001b[1m1242/1242\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m51s\u001b[0m 41ms/step - binary_accuracy: 0.8586 - loss: 0.3115 - val_binary_accuracy: 0.8529 - val_loss: 0.3206\n",
      "Epoch 4/100\n",
      "\u001b[1m1242/1242\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m53s\u001b[0m 43ms/step - binary_accuracy: 0.8672 - loss: 0.2946 - val_binary_accuracy: 0.8613 - val_loss: 0.3038\n",
      "Epoch 5/100\n",
      "\u001b[1m1242/1242\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m57s\u001b[0m 46ms/step - binary_accuracy: 0.8732 - loss: 0.2801 - val_binary_accuracy: 0.8656 - val_loss: 0.2966\n",
      "Epoch 6/100\n",
      "\u001b[1m1242/1242\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m54s\u001b[0m 44ms/step - binary_accuracy: 0.8783 - loss: 0.2686 - val_binary_accuracy: 0.8664 - val_loss: 0.2920\n",
      "Epoch 7/100\n",
      "\u001b[1m1242/1242\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m57s\u001b[0m 46ms/step - binary_accuracy: 0.8847 - loss: 0.2557 - val_binary_accuracy: 0.8658 - val_loss: 0.2916\n",
      "Epoch 8/100\n",
      "\u001b[1m1242/1242\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m59s\u001b[0m 48ms/step - binary_accuracy: 0.8879 - loss: 0.2486 - val_binary_accuracy: 0.8691 - val_loss: 0.2871\n",
      "Epoch 9/100\n",
      "\u001b[1m1242/1242\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m57s\u001b[0m 46ms/step - binary_accuracy: 0.8932 - loss: 0.2376 - val_binary_accuracy: 0.8649 - val_loss: 0.2936\n",
      "Epoch 10/100\n",
      "\u001b[1m1242/1242\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m56s\u001b[0m 45ms/step - binary_accuracy: 0.8975 - loss: 0.2285 - val_binary_accuracy: 0.8709 - val_loss: 0.2841\n",
      "Epoch 11/100\n",
      "\u001b[1m1242/1242\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m56s\u001b[0m 45ms/step - binary_accuracy: 0.9024 - loss: 0.2174 - val_binary_accuracy: 0.8691 - val_loss: 0.2870\n",
      "Epoch 12/100\n",
      "\u001b[1m1242/1242\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m56s\u001b[0m 45ms/step - binary_accuracy: 0.9055 - loss: 0.2115 - val_binary_accuracy: 0.8720 - val_loss: 0.2836\n",
      "Epoch 13/100\n",
      "\u001b[1m1242/1242\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m54s\u001b[0m 44ms/step - binary_accuracy: 0.9095 - loss: 0.2035 - val_binary_accuracy: 0.8715 - val_loss: 0.2829\n",
      "Epoch 14/100\n",
      "\u001b[1m1242/1242\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m58s\u001b[0m 47ms/step - binary_accuracy: 0.9116 - loss: 0.1988 - val_binary_accuracy: 0.8731 - val_loss: 0.2836\n",
      "Epoch 15/100\n",
      "\u001b[1m1242/1242\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m57s\u001b[0m 46ms/step - binary_accuracy: 0.9148 - loss: 0.1927 - val_binary_accuracy: 0.8742 - val_loss: 0.2821\n",
      "Epoch 16/100\n",
      "\u001b[1m1242/1242\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m57s\u001b[0m 45ms/step - binary_accuracy: 0.9170 - loss: 0.1871 - val_binary_accuracy: 0.8727 - val_loss: 0.2859\n",
      "Epoch 17/100\n",
      "\u001b[1m1242/1242\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m54s\u001b[0m 44ms/step - binary_accuracy: 0.9195 - loss: 0.1806 - val_binary_accuracy: 0.8758 - val_loss: 0.2823\n",
      "Epoch 18/100\n",
      "\u001b[1m1242/1242\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m61s\u001b[0m 49ms/step - binary_accuracy: 0.9217 - loss: 0.1771 - val_binary_accuracy: 0.8734 - val_loss: 0.2896\n",
      "Epoch 19/100\n",
      "\u001b[1m1242/1242\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m58s\u001b[0m 47ms/step - binary_accuracy: 0.9237 - loss: 0.1725 - val_binary_accuracy: 0.8756 - val_loss: 0.2902\n",
      "Epoch 20/100\n",
      "\u001b[1m1242/1242\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m57s\u001b[0m 46ms/step - binary_accuracy: 0.9254 - loss: 0.1687 - val_binary_accuracy: 0.8769 - val_loss: 0.2874\n",
      "Epoch 21/100\n",
      "\u001b[1m1242/1242\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m56s\u001b[0m 45ms/step - binary_accuracy: 0.9271 - loss: 0.1650 - val_binary_accuracy: 0.8769 - val_loss: 0.2875\n",
      "Epoch 22/100\n",
      "\u001b[1m1242/1242\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m57s\u001b[0m 46ms/step - binary_accuracy: 0.9292 - loss: 0.1609 - val_binary_accuracy: 0.8748 - val_loss: 0.2918\n",
      "Epoch 23/100\n",
      "\u001b[1m1242/1242\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m57s\u001b[0m 46ms/step - binary_accuracy: 0.9293 - loss: 0.1596 - val_binary_accuracy: 0.8774 - val_loss: 0.2880\n",
      "Epoch 24/100\n",
      "\u001b[1m1242/1242\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m58s\u001b[0m 46ms/step - binary_accuracy: 0.9308 - loss: 0.1569 - val_binary_accuracy: 0.8759 - val_loss: 0.2931\n",
      "Epoch 25/100\n",
      "\u001b[1m1242/1242\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m55s\u001b[0m 44ms/step - binary_accuracy: 0.9318 - loss: 0.1549 - val_binary_accuracy: 0.8790 - val_loss: 0.2932\n",
      "Epoch 26/100\n",
      "\u001b[1m1242/1242\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m54s\u001b[0m 43ms/step - binary_accuracy: 0.9328 - loss: 0.1527 - val_binary_accuracy: 0.8783 - val_loss: 0.2956\n",
      "Epoch 27/100\n",
      "\u001b[1m1242/1242\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m56s\u001b[0m 45ms/step - binary_accuracy: 0.9345 - loss: 0.1493 - val_binary_accuracy: 0.8795 - val_loss: 0.2920\n",
      "Epoch 28/100\n",
      "\u001b[1m1242/1242\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m54s\u001b[0m 44ms/step - binary_accuracy: 0.9348 - loss: 0.1481 - val_binary_accuracy: 0.8794 - val_loss: 0.2927\n",
      "Epoch 29/100\n",
      "\u001b[1m1242/1242\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m54s\u001b[0m 43ms/step - binary_accuracy: 0.9354 - loss: 0.1462 - val_binary_accuracy: 0.8806 - val_loss: 0.2915\n",
      "Epoch 30/100\n",
      "\u001b[1m1242/1242\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m53s\u001b[0m 43ms/step - binary_accuracy: 0.9365 - loss: 0.1449 - val_binary_accuracy: 0.8810 - val_loss: 0.2906\n",
      "Epoch 31/100\n",
      "\u001b[1m1242/1242\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m53s\u001b[0m 42ms/step - binary_accuracy: 0.9369 - loss: 0.1436 - val_binary_accuracy: 0.8811 - val_loss: 0.2927\n",
      "Epoch 32/100\n",
      "\u001b[1m1242/1242\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m52s\u001b[0m 42ms/step - binary_accuracy: 0.9377 - loss: 0.1418 - val_binary_accuracy: 0.8807 - val_loss: 0.2942\n",
      "Epoch 33/100\n",
      "\u001b[1m1242/1242\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m53s\u001b[0m 42ms/step - binary_accuracy: 0.9379 - loss: 0.1411 - val_binary_accuracy: 0.8803 - val_loss: 0.2987\n",
      "Epoch 34/100\n",
      "\u001b[1m1242/1242\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m52s\u001b[0m 42ms/step - binary_accuracy: 0.9381 - loss: 0.1403 - val_binary_accuracy: 0.8824 - val_loss: 0.3019\n",
      "Epoch 35/100\n",
      "\u001b[1m1242/1242\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m52s\u001b[0m 42ms/step - binary_accuracy: 0.9389 - loss: 0.1388 - val_binary_accuracy: 0.8807 - val_loss: 0.3022\n",
      "Epoch 36/100\n",
      "\u001b[1m1242/1242\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m52s\u001b[0m 42ms/step - binary_accuracy: 0.9395 - loss: 0.1377 - val_binary_accuracy: 0.8788 - val_loss: 0.2967\n",
      "Epoch 37/100\n",
      "\u001b[1m1242/1242\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m54s\u001b[0m 43ms/step - binary_accuracy: 0.9395 - loss: 0.1372 - val_binary_accuracy: 0.8819 - val_loss: 0.2992\n",
      "Epoch 38/100\n",
      "\u001b[1m1242/1242\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m53s\u001b[0m 43ms/step - binary_accuracy: 0.9414 - loss: 0.1337 - val_binary_accuracy: 0.8805 - val_loss: 0.3031\n",
      "Epoch 39/100\n",
      "\u001b[1m1242/1242\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m52s\u001b[0m 42ms/step - binary_accuracy: 0.9409 - loss: 0.1347 - val_binary_accuracy: 0.8801 - val_loss: 0.3027\n",
      "Epoch 40/100\n",
      "\u001b[1m1242/1242\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m55s\u001b[0m 44ms/step - binary_accuracy: 0.9411 - loss: 0.1339 - val_binary_accuracy: 0.8821 - val_loss: 0.2989\n",
      "Epoch 41/100\n",
      "\u001b[1m1242/1242\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m53s\u001b[0m 43ms/step - binary_accuracy: 0.9416 - loss: 0.1325 - val_binary_accuracy: 0.8799 - val_loss: 0.3008\n",
      "Epoch 42/100\n",
      "\u001b[1m1242/1242\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m54s\u001b[0m 43ms/step - binary_accuracy: 0.9416 - loss: 0.1323 - val_binary_accuracy: 0.8822 - val_loss: 0.3035\n",
      "Epoch 43/100\n",
      "\u001b[1m1242/1242\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m54s\u001b[0m 43ms/step - binary_accuracy: 0.9425 - loss: 0.1302 - val_binary_accuracy: 0.8836 - val_loss: 0.3055\n",
      "Epoch 44/100\n",
      "\u001b[1m1242/1242\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m55s\u001b[0m 44ms/step - binary_accuracy: 0.9431 - loss: 0.1291 - val_binary_accuracy: 0.8818 - val_loss: 0.3049\n",
      "Epoch 45/100\n",
      "\u001b[1m1242/1242\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m52s\u001b[0m 42ms/step - binary_accuracy: 0.9432 - loss: 0.1292 - val_binary_accuracy: 0.8830 - val_loss: 0.3059\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 46/100\n",
      "\u001b[1m1242/1242\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m52s\u001b[0m 42ms/step - binary_accuracy: 0.9432 - loss: 0.1288 - val_binary_accuracy: 0.8830 - val_loss: 0.3108\n",
      "Epoch 47/100\n",
      "\u001b[1m1242/1242\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m52s\u001b[0m 42ms/step - binary_accuracy: 0.9430 - loss: 0.1290 - val_binary_accuracy: 0.8820 - val_loss: 0.3065\n",
      "Epoch 48/100\n",
      "\u001b[1m1242/1242\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m52s\u001b[0m 42ms/step - binary_accuracy: 0.9438 - loss: 0.1272 - val_binary_accuracy: 0.8835 - val_loss: 0.3091\n",
      "Epoch 49/100\n",
      "\u001b[1m1242/1242\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m52s\u001b[0m 42ms/step - binary_accuracy: 0.9445 - loss: 0.1262 - val_binary_accuracy: 0.8837 - val_loss: 0.3026\n",
      "Epoch 50/100\n",
      "\u001b[1m1242/1242\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m52s\u001b[0m 42ms/step - binary_accuracy: 0.9449 - loss: 0.1246 - val_binary_accuracy: 0.8829 - val_loss: 0.3101\n",
      "Epoch 51/100\n",
      "\u001b[1m1242/1242\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m52s\u001b[0m 42ms/step - binary_accuracy: 0.9453 - loss: 0.1243 - val_binary_accuracy: 0.8845 - val_loss: 0.3082\n",
      "Epoch 52/100\n",
      "\u001b[1m1242/1242\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m52s\u001b[0m 42ms/step - binary_accuracy: 0.9455 - loss: 0.1241 - val_binary_accuracy: 0.8839 - val_loss: 0.3018\n",
      "Epoch 53/100\n",
      "\u001b[1m1242/1242\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m52s\u001b[0m 42ms/step - binary_accuracy: 0.9454 - loss: 0.1239 - val_binary_accuracy: 0.8830 - val_loss: 0.3105\n",
      "Epoch 54/100\n",
      "\u001b[1m1242/1242\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m54s\u001b[0m 43ms/step - binary_accuracy: 0.9458 - loss: 0.1230 - val_binary_accuracy: 0.8835 - val_loss: 0.3041\n",
      "Epoch 55/100\n",
      "\u001b[1m1242/1242\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m53s\u001b[0m 43ms/step - binary_accuracy: 0.9460 - loss: 0.1225 - val_binary_accuracy: 0.8838 - val_loss: 0.3047\n",
      "Epoch 56/100\n",
      "\u001b[1m1242/1242\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m52s\u001b[0m 42ms/step - binary_accuracy: 0.9464 - loss: 0.1213 - val_binary_accuracy: 0.8850 - val_loss: 0.3090\n",
      "Epoch 57/100\n",
      "\u001b[1m1242/1242\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m52s\u001b[0m 42ms/step - binary_accuracy: 0.9466 - loss: 0.1203 - val_binary_accuracy: 0.8847 - val_loss: 0.3091\n",
      "Epoch 58/100\n",
      "\u001b[1m1242/1242\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m52s\u001b[0m 42ms/step - binary_accuracy: 0.9462 - loss: 0.1214 - val_binary_accuracy: 0.8836 - val_loss: 0.3065\n",
      "Epoch 59/100\n",
      "\u001b[1m1242/1242\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m52s\u001b[0m 42ms/step - binary_accuracy: 0.9467 - loss: 0.1208 - val_binary_accuracy: 0.8842 - val_loss: 0.3086\n",
      "Epoch 60/100\n",
      "\u001b[1m1242/1242\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m52s\u001b[0m 42ms/step - binary_accuracy: 0.9469 - loss: 0.1205 - val_binary_accuracy: 0.8849 - val_loss: 0.3173\n",
      "Epoch 61/100\n",
      "\u001b[1m1242/1242\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m52s\u001b[0m 42ms/step - binary_accuracy: 0.9475 - loss: 0.1192 - val_binary_accuracy: 0.8834 - val_loss: 0.3151\n",
      "Epoch 62/100\n",
      "\u001b[1m1242/1242\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m52s\u001b[0m 42ms/step - binary_accuracy: 0.9476 - loss: 0.1187 - val_binary_accuracy: 0.8838 - val_loss: 0.3084\n",
      "Epoch 63/100\n",
      "\u001b[1m1242/1242\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m52s\u001b[0m 42ms/step - binary_accuracy: 0.9477 - loss: 0.1185 - val_binary_accuracy: 0.8828 - val_loss: 0.3073\n",
      "Epoch 64/100\n",
      "\u001b[1m1242/1242\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m52s\u001b[0m 42ms/step - binary_accuracy: 0.9473 - loss: 0.1192 - val_binary_accuracy: 0.8850 - val_loss: 0.3110\n",
      "Epoch 65/100\n",
      "\u001b[1m1242/1242\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m52s\u001b[0m 42ms/step - binary_accuracy: 0.9477 - loss: 0.1187 - val_binary_accuracy: 0.8857 - val_loss: 0.3222\n",
      "Epoch 66/100\n",
      "\u001b[1m1242/1242\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m52s\u001b[0m 42ms/step - binary_accuracy: 0.9481 - loss: 0.1177 - val_binary_accuracy: 0.8856 - val_loss: 0.3219\n",
      "Epoch 67/100\n",
      "\u001b[1m1242/1242\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m52s\u001b[0m 42ms/step - binary_accuracy: 0.9478 - loss: 0.1183 - val_binary_accuracy: 0.8845 - val_loss: 0.3170\n",
      "Epoch 68/100\n",
      "\u001b[1m1242/1242\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m54s\u001b[0m 43ms/step - binary_accuracy: 0.9488 - loss: 0.1159 - val_binary_accuracy: 0.8853 - val_loss: 0.3106\n",
      "Epoch 69/100\n",
      "\u001b[1m1242/1242\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m54s\u001b[0m 43ms/step - binary_accuracy: 0.9491 - loss: 0.1148 - val_binary_accuracy: 0.8856 - val_loss: 0.3123\n",
      "Epoch 70/100\n",
      "\u001b[1m1242/1242\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m52s\u001b[0m 42ms/step - binary_accuracy: 0.9492 - loss: 0.1152 - val_binary_accuracy: 0.8843 - val_loss: 0.3234\n",
      "Epoch 71/100\n",
      "\u001b[1m1242/1242\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m53s\u001b[0m 43ms/step - binary_accuracy: 0.9490 - loss: 0.1153 - val_binary_accuracy: 0.8843 - val_loss: 0.3111\n",
      "Epoch 72/100\n",
      "\u001b[1m1242/1242\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m52s\u001b[0m 42ms/step - binary_accuracy: 0.9490 - loss: 0.1152 - val_binary_accuracy: 0.8844 - val_loss: 0.3157\n",
      "Epoch 73/100\n",
      "\u001b[1m1242/1242\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m53s\u001b[0m 42ms/step - binary_accuracy: 0.9500 - loss: 0.1135 - val_binary_accuracy: 0.8834 - val_loss: 0.3124\n",
      "Epoch 74/100\n",
      "\u001b[1m1242/1242\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m52s\u001b[0m 42ms/step - binary_accuracy: 0.9494 - loss: 0.1146 - val_binary_accuracy: 0.8846 - val_loss: 0.3145\n",
      "Epoch 75/100\n",
      "\u001b[1m1242/1242\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m52s\u001b[0m 42ms/step - binary_accuracy: 0.9495 - loss: 0.1143 - val_binary_accuracy: 0.8863 - val_loss: 0.3239\n",
      "Epoch 76/100\n",
      "\u001b[1m1242/1242\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m52s\u001b[0m 42ms/step - binary_accuracy: 0.9500 - loss: 0.1137 - val_binary_accuracy: 0.8856 - val_loss: 0.3225\n",
      "Epoch 77/100\n",
      "\u001b[1m1242/1242\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m53s\u001b[0m 43ms/step - binary_accuracy: 0.9497 - loss: 0.1138 - val_binary_accuracy: 0.8850 - val_loss: 0.3219\n",
      "Epoch 78/100\n",
      "\u001b[1m1242/1242\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m53s\u001b[0m 43ms/step - binary_accuracy: 0.9502 - loss: 0.1124 - val_binary_accuracy: 0.8860 - val_loss: 0.3248\n",
      "Epoch 79/100\n",
      "\u001b[1m1242/1242\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m53s\u001b[0m 43ms/step - binary_accuracy: 0.9507 - loss: 0.1115 - val_binary_accuracy: 0.8850 - val_loss: 0.3147\n",
      "Epoch 80/100\n",
      "\u001b[1m1242/1242\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m54s\u001b[0m 43ms/step - binary_accuracy: 0.9501 - loss: 0.1125 - val_binary_accuracy: 0.8855 - val_loss: 0.3224\n",
      "Epoch 81/100\n",
      "\u001b[1m1242/1242\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m54s\u001b[0m 43ms/step - binary_accuracy: 0.9505 - loss: 0.1122 - val_binary_accuracy: 0.8840 - val_loss: 0.3129\n",
      "Epoch 82/100\n",
      "\u001b[1m1242/1242\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m59s\u001b[0m 47ms/step - binary_accuracy: 0.9504 - loss: 0.1116 - val_binary_accuracy: 0.8858 - val_loss: 0.3188\n",
      "Epoch 83/100\n",
      "\u001b[1m1242/1242\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m55s\u001b[0m 44ms/step - binary_accuracy: 0.9509 - loss: 0.1112 - val_binary_accuracy: 0.8862 - val_loss: 0.3347\n",
      "Epoch 84/100\n",
      "\u001b[1m1242/1242\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m57s\u001b[0m 46ms/step - binary_accuracy: 0.9513 - loss: 0.1101 - val_binary_accuracy: 0.8862 - val_loss: 0.3299\n",
      "Epoch 85/100\n",
      "\u001b[1m1242/1242\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m54s\u001b[0m 44ms/step - binary_accuracy: 0.9513 - loss: 0.1100 - val_binary_accuracy: 0.8859 - val_loss: 0.3234\n",
      "Epoch 86/100\n",
      "\u001b[1m1242/1242\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m63s\u001b[0m 50ms/step - binary_accuracy: 0.9509 - loss: 0.1113 - val_binary_accuracy: 0.8856 - val_loss: 0.3257\n",
      "Epoch 87/100\n",
      "\u001b[1m1242/1242\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m59s\u001b[0m 47ms/step - binary_accuracy: 0.9510 - loss: 0.1104 - val_binary_accuracy: 0.8867 - val_loss: 0.3291\n",
      "Epoch 88/100\n",
      "\u001b[1m1242/1242\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m58s\u001b[0m 47ms/step - binary_accuracy: 0.9511 - loss: 0.1104 - val_binary_accuracy: 0.8848 - val_loss: 0.3155\n",
      "Epoch 89/100\n",
      "\u001b[1m1242/1242\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m57s\u001b[0m 46ms/step - binary_accuracy: 0.9513 - loss: 0.1102 - val_binary_accuracy: 0.8867 - val_loss: 0.3215\n",
      "Epoch 90/100\n",
      "\u001b[1m1242/1242\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m57s\u001b[0m 46ms/step - binary_accuracy: 0.9520 - loss: 0.1082 - val_binary_accuracy: 0.8862 - val_loss: 0.3276\n",
      "Epoch 91/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1242/1242\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m57s\u001b[0m 46ms/step - binary_accuracy: 0.9517 - loss: 0.1092 - val_binary_accuracy: 0.8856 - val_loss: 0.3212\n",
      "Epoch 92/100\n",
      "\u001b[1m1242/1242\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m58s\u001b[0m 47ms/step - binary_accuracy: 0.9519 - loss: 0.1086 - val_binary_accuracy: 0.8866 - val_loss: 0.3191\n",
      "Epoch 93/100\n",
      "\u001b[1m1242/1242\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m57s\u001b[0m 46ms/step - binary_accuracy: 0.9525 - loss: 0.1075 - val_binary_accuracy: 0.8862 - val_loss: 0.3236\n",
      "Epoch 94/100\n",
      "\u001b[1m1242/1242\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m61s\u001b[0m 49ms/step - binary_accuracy: 0.9524 - loss: 0.1075 - val_binary_accuracy: 0.8856 - val_loss: 0.3134\n",
      "Epoch 95/100\n",
      "\u001b[1m1242/1242\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m71s\u001b[0m 57ms/step - binary_accuracy: 0.9525 - loss: 0.1074 - val_binary_accuracy: 0.8861 - val_loss: 0.3267\n",
      "Epoch 96/100\n",
      "\u001b[1m1242/1242\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m63s\u001b[0m 50ms/step - binary_accuracy: 0.9523 - loss: 0.1079 - val_binary_accuracy: 0.8875 - val_loss: 0.3199\n",
      "Epoch 97/100\n",
      "\u001b[1m1242/1242\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m60s\u001b[0m 49ms/step - binary_accuracy: 0.9526 - loss: 0.1073 - val_binary_accuracy: 0.8871 - val_loss: 0.3286\n",
      "Epoch 98/100\n",
      "\u001b[1m1242/1242\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m59s\u001b[0m 47ms/step - binary_accuracy: 0.9528 - loss: 0.1071 - val_binary_accuracy: 0.8873 - val_loss: 0.3251\n",
      "Epoch 99/100\n",
      "\u001b[1m1242/1242\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m59s\u001b[0m 48ms/step - binary_accuracy: 0.9526 - loss: 0.1073 - val_binary_accuracy: 0.8859 - val_loss: 0.3244\n",
      "Epoch 100/100\n",
      "\u001b[1m1242/1242\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m58s\u001b[0m 47ms/step - binary_accuracy: 0.9531 - loss: 0.1061 - val_binary_accuracy: 0.8867 - val_loss: 0.3225\n",
      "========================================================================================\n",
      "= TWOSIDES_00.pkl\n",
      "========================================================================================\n",
      "= Model loss, accuracy on the train set: 0.13660 94.60\n",
      "= Model loss, accuracy on the  test set: 0.16484 100.00\n",
      "========================================================================================\n"
     ]
    }
   ],
   "source": [
    "run_experiment('TWOSIDES_00', 1, 0.25, size, targets, \\\n",
    "               'sigmoid', BinaryCrossentropy(from_logits=False), 0.0001, 'binary_accuracy', \\\n",
    "               x_train, y_train, x_test, y_test, \\\n",
    "               100, 100, 0.2, 1)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8521dde4",
   "metadata": {},
   "source": [
    "#### View Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "33375d76",
   "metadata": {},
   "outputs": [],
   "source": [
    "def view_results(filename, x_train, y_train, x_test, y_test):\n",
    "    with open(filename, 'rb') as file:\n",
    "        model = pickle.load(file)\n",
    "        history = pickle.load(file)\n",
    "    print('====================================================================================')\n",
    "    print('=== Model:', filename)\n",
    "    print('===')\n",
    "    if len(x_test) < 100:\n",
    "        x_test = x_train\n",
    "        y_test = y_train\n",
    "    loss, acc = model.evaluate(x_test, y_test, verbose=0)\n",
    "    print(f'=== binary_accuracy {acc:.6f}, loss {loss:.6f}')\n",
    "    y_pred = model.predict(x_test, verbose=0)\n",
    "    print(f'=== MSE:      {mean_squared_error(y_test, y_pred):.6f}')\n",
    "    print(f'=== R2 score: {r2_score(y_test, y_pred):.6f}')\n",
    "    print('===')\n",
    "    print('===  Precision - Recall')\n",
    "    print(f'===     {precision_score(y_test, y_pred.round(), average=\"macro\"):.4f} - \\\n",
    "{recall_score(y_test, y_pred.round(), average=\"macro\"):.4f}')\n",
    "    for c in range(0, y_pred.shape[1]):\n",
    "        print(f'=== {c}: {precision_score(y_test[:,c], y_pred.round()[:,c]):.4f} - {recall_score(y_test[:,c], y_pred.round()[:,c]):.4f}')\n",
    "    return model, history, y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b401b4dc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "====================================================================================\n",
      "=== Model: TWOSIDES_00.pkl\n",
      "===\n",
      "=== binary_accuracy 0.946010, loss 0.136599\n",
      "=== MSE:      0.039301\n",
      "=== R2 score: 0.727747\n",
      "===\n",
      "===  Precision - Recall\n",
      "===     0.8446 - 0.8380\n",
      "=== 0: 0.9898 - 0.9776\n",
      "=== 1: 0.8664 - 0.9508\n",
      "=== 2: 0.8929 - 0.9779\n",
      "=== 3: 0.7075 - 0.5451\n",
      "=== 4: 0.9428 - 0.9811\n",
      "=== 5: 0.7371 - 0.5086\n",
      "=== 6: 0.9473 - 0.9814\n",
      "=== 7: 0.7790 - 0.7340\n",
      "=== 8: 0.8430 - 0.8386\n",
      "=== 9: 0.8190 - 0.8234\n",
      "=== 10: 0.9534 - 0.9820\n",
      "=== 11: 0.9226 - 0.9770\n",
      "=== 12: 0.8831 - 0.9481\n",
      "=== 13: 0.9221 - 0.9801\n",
      "=== 14: 0.7547 - 0.6709\n",
      "=== 15: 0.9264 - 0.9796\n",
      "=== 16: 0.8684 - 0.9421\n",
      "=== 17: 0.8407 - 0.8908\n",
      "=== 18: 0.7496 - 0.6453\n",
      "=== 19: 0.9424 - 0.9810\n",
      "=== 20: 0.8437 - 0.9336\n",
      "=== 21: 0.7073 - 0.5068\n",
      "=== 22: 0.9209 - 0.9774\n",
      "=== 23: 0.8228 - 0.9263\n",
      "=== 24: 0.8918 - 0.9625\n",
      "=== 25: 0.9144 - 0.9769\n",
      "=== 26: 0.7117 - 0.1353\n",
      "=== 27: 0.9238 - 0.9792\n",
      "=== 28: 0.7775 - 0.8913\n",
      "=== 29: 0.9162 - 0.9767\n",
      "=== 30: 0.8482 - 0.9346\n",
      "=== 31: 0.8856 - 0.9551\n",
      "=== 32: 0.8654 - 0.9456\n",
      "=== 33: 0.9059 - 0.9709\n",
      "=== 34: 0.9354 - 0.9812\n",
      "=== 35: 0.9341 - 0.9805\n",
      "=== 36: 0.8736 - 0.9608\n",
      "=== 37: 0.7906 - 0.8381\n",
      "=== 38: 0.7900 - 0.8806\n",
      "=== 39: 0.7843 - 0.7885\n",
      "=== 40: 0.9292 - 0.9808\n",
      "=== 41: 0.6838 - 0.4405\n",
      "=== 42: 0.8668 - 0.9680\n",
      "=== 43: 0.7308 - 0.6838\n",
      "=== 44: 0.9270 - 0.9789\n",
      "=== 45: 0.9230 - 0.9751\n",
      "=== 46: 0.7178 - 0.6319\n",
      "=== 47: 0.9090 - 0.9802\n",
      "=== 48: 0.7309 - 0.6292\n",
      "=== 49: 0.7154 - 0.2528\n",
      "=== 50: 0.6650 - 0.2970\n",
      "=== 51: 0.7918 - 0.9309\n",
      "=== 52: 0.9301 - 0.9811\n",
      "=== 53: 0.7583 - 0.7024\n"
     ]
    }
   ],
   "source": [
    "model, history, y_pred = view_results(\n",
    "    'TWOSIDES_00.pkl', \n",
    "    x_train, y_train, x_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8cfce33c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

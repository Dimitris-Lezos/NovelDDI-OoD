{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7b37d784",
   "metadata": {},
   "source": [
    "### Produce BioBERT embeddings for Drugs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dff781dc",
   "metadata": {},
   "source": [
    "#### Import libraries and BioBERT model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c56182cf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: progressbar2 in c:\\users\\dlezo\\appdata\\roaming\\python\\python311\\site-packages (4.5.0)\n",
      "Requirement already satisfied: python-utils>=3.8.1 in c:\\users\\dlezo\\appdata\\roaming\\python\\python311\\site-packages (from progressbar2) (3.9.1)\n",
      "Requirement already satisfied: typing_extensions>3.10.0.2 in c:\\software\\anaconda3\\lib\\site-packages (from python-utils>=3.8.1->progressbar2) (4.7.1)\n"
     ]
    }
   ],
   "source": [
    "!pip install progressbar2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4e218854",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\dlezo\\AppData\\Roaming\\Python\\Python311\\site-packages\\pandas\\core\\arrays\\masked.py:60: UserWarning: Pandas requires version '1.3.6' or newer of 'bottleneck' (version '1.3.5' currently installed).\n",
      "  from pandas.core import (\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\dlezo\\AppData\\Roaming\\Python\\Python311\\site-packages\\tf_keras\\src\\losses.py:2976: The name tf.losses.sparse_softmax_cross_entropy is deprecated. Please use tf.compat.v1.losses.sparse_softmax_cross_entropy instead.\n",
      "\n",
      "WARNING:tensorflow:From C:\\Users\\dlezo\\AppData\\Roaming\\Python\\Python311\\site-packages\\tf_keras\\src\\backend.py:873: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "All PyTorch model weights were used when initializing TFBertModel.\n",
      "\n",
      "All the weights of TFBertModel were initialized from the PyTorch model.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use TFBertModel for predictions without further training.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import torch\n",
    "from transformers import BertTokenizer, TFBertModel\n",
    "import pickle\n",
    "import json\n",
    "import numpy as np\n",
    "from progressbar import ProgressBar\n",
    "\n",
    "tokenizer = BertTokenizer.from_pretrained('dmis-lab/biobert-v1.1')\n",
    "model = TFBertModel.from_pretrained('dmis-lab/biobert-v1.1', from_pt=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da317e6d",
   "metadata": {},
   "source": [
    "#### Load the Drugs common names from DrugBank"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a4f83382",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('./Data/TWOSIDES/rx_norm_to_name.pkl', 'rb') as file:\n",
    "    rx_norm_to_name = pickle.load(file)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a8bd574",
   "metadata": {},
   "source": [
    "#### Get the embedding from BioBERT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e000e0ca",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[38;2;0;255;0m100%\u001b[39m \u001b[38;2;0;255;0m(100 of 100)\u001b[39m |######################| Elapsed Time: 0:08:20 Time:  0:08:200444\n"
     ]
    }
   ],
   "source": [
    "embeddings = {}\n",
    "i = 0\n",
    "step = len(rx_norm_to_name.keys())//100\n",
    "bar = ProgressBar(max_value=100)\n",
    "for rx_norm_id in rx_norm_to_name.keys():\n",
    "    if i%step==0:\n",
    "        bar.next()\n",
    "    encoded_input = tokenizer(rx_norm_to_name[rx_norm_id], return_tensors='tf')\n",
    "    output_embedding = model(encoded_input)['last_hidden_state'][:,0,:]\n",
    "    embeddings[rx_norm_id] = output_embedding\n",
    "    i += 1\n",
    "bar.finish()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f606224b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the embeddings in a list\n",
    "embeddings768 = []\n",
    "for rx_norm_id in rx_norm_to_name.keys():\n",
    "    embeddings768.append(embeddings[rx_norm_id].numpy()[0])\n",
    "embeddings768 = np.array(embeddings768)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b46c02f2",
   "metadata": {},
   "source": [
    "#### Reduce the embeddings dimensionality with PCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "5a7d515b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of components: 128\n",
      "Covariance covered: 0.9049438\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from sklearn.decomposition import PCA\n",
    "\n",
    "size = 128\n",
    "pca = PCA(n_components=size, svd_solver='full')\n",
    "embeddings_pca = pca.fit_transform(embeddings768)\n",
    "\n",
    "print('Number of components:', pca.n_components_)\n",
    "print('Covariance covered:', pca.explained_variance_ratio_.sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "56335294",
   "metadata": {},
   "outputs": [],
   "source": [
    "embeddings_size_pca = {}\n",
    "i = 0\n",
    "for rx_norm_id in embeddings.keys():\n",
    "    embeddings_size_pca[rx_norm_id] = embeddings_pca[i]\n",
    "    i += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "4ed4befe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "./Data/TWOSIDES-biobert_embeddings_128_pca.pkl\n"
     ]
    }
   ],
   "source": [
    "with open('./Data/Embeddings/biobert_embeddings_'+str(size)+'_pca.pkl', 'wb') as file:\n",
    "    pickle.dump(embeddings_size_pca, file)\n",
    "    print(file.name)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5151294",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
